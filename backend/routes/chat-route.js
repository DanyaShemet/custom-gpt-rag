// ðŸ“ backend/routes/chatRoute.js (Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¹ Ð±ÐµÐ· chromadb)
import express from 'express'
import fs from 'fs'
import path from 'path'
import OpenAI from 'openai'
import { cosineSimilarity } from '../utils/cosine-similarity.js'

const router = express.Router()
const DATA_DIR = path.resolve('user_data')
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

// ðŸ§  GPT Ñ‡Ð°Ñ‚ Ð· Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ð¸Ð¼ Ð¿Ð¾ÑˆÑƒÐºÐ¾Ð¼ Ð¿Ð¾ user_{sessionId}.json
router.post('/api/chat', async (req, res) => {
    const { question, sessionId } = req.body
    if (!question || !sessionId) {
        return res.status(400).json({ message: 'ÐŸÐ¾Ñ‚Ñ€Ñ–Ð±Ð½Ð¾ question Ñ– sessionId.' })
    }

    const filepath = path.join(DATA_DIR, `user_${sessionId}.json`)
    if (!fs.existsSync(filepath)) {
        return res.json({ reply: 'Ð£ Ð²Ð°Ñ Ñ‰Ðµ Ð½ÐµÐ¼Ð°Ñ” Ð±Ð°Ð·Ð¸ Ð·Ð½Ð°Ð½ÑŒ. Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ñ‚Ðµ PDF.' })
    }

    const chunks = JSON.parse(fs.readFileSync(filepath, 'utf-8'))
    const questionEmbedding = await getEmbedding(question)

    const scoredChunks = await Promise.all(
        chunks.map(async (chunk) => {
            const emb = await getEmbedding(chunk)
            const score = cosineSimilarity(questionEmbedding, emb)
            return { chunk, score }
        })
    )

    const topChunks = scoredChunks
        .sort((a, b) => b.score - a.score)
        .slice(0, 3)
        .map((item) => item.chunk)

    const context = topChunks.join('\n---\n')

    const completion = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
            {
                role: 'system',
                content: 'Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ Ð»Ð¸ÑˆÐµ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– Ð½Ð°Ð´Ð°Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ. Ð¯ÐºÑ‰Ð¾ Ð½Ðµ Ð·Ð½Ð°Ñ”Ñˆ â€” ÑÐºÐ°Ð¶Ð¸, Ñ‰Ð¾ Ð½Ðµ Ð·Ð½Ð°Ñ”Ñˆ.'
            },
            {
                role: 'user',
                content: `ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:\n${context}\n\nÐŸÐ¸Ñ‚Ð°Ð½Ð½Ñ: ${question}`
            }
        ]
    })

    res.json({ reply: completion.choices[0].message.content })
})

async function getEmbedding(text) {
    const res = await openai.embeddings.create({
        model: 'text-embedding-3-small',
        input: text
    })
    return res.data[0].embedding
}

// ðŸ” ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° ÐºÑ–Ð»ÑŒÐºÐ¾ÑÑ‚Ñ– Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ–Ð²
router.get('/api/status/:sessionId', async (req, res) => {
    const { sessionId } = req.params
    const filepath = path.join(DATA_DIR, `user_${sessionId}.json`)
    if (!fs.existsSync(filepath)) return res.json({ count: 0 })
    const chunks = JSON.parse(fs.readFileSync(filepath, 'utf-8'))
    res.json({ count: chunks.length })
})

// ðŸ§¨ Ð¡ÐºÐ¸Ð´Ð°Ð½Ð½Ñ Ð·Ð½Ð°Ð½ÑŒ
router.delete('/api/reset/:sessionId', async (req, res) => {
    const { sessionId } = req.params
    const filepath = path.join(DATA_DIR, `user_${sessionId}.json`)
    if (fs.existsSync(filepath)) fs.unlinkSync(filepath)
    res.json({ message: 'Ð‘Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½ÑŒ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð¾.' })
})


export default router
